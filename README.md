# SatelliteBuildingArea
Определение площади застройки по спутниковому снимку.

## Эксперимент 1: сегментация зданий на спутниковых снимках (DeepLabV3)

Ноутбук: 1. Buildings_ResNet.ipynb

**Цель:** обучить модель бинарной сегментации зданий (маска 0/1) по спутниковым TIFF.

### Данные и разбиение
- Структура датасета: `dataset/images/*.tif` и `dataset/gt/*.tif` (маски с теми же именами файлов).
- Разбиение: train/val = 85/15 (фиксированный `seed=42`).

### Пайплайн данных
- Чтение больших TIFF “окнами” (`rasterio`), генерация случайных патчей на лету.
- Размер патча: **256×256**.
- Train: **scale jitter 0.5–1.5** + аугментации (**flip**, **rot90**).
- Val: без scale jitter и без аугментаций.
- Нормализация изображения в диапазон **[0, 1]**; маска бинаризуется **0/255 → 0/1**.

### Модель
- `DeepLabV3-ResNet50` (torchvision), `num_classes=1` (логиты для бинарной сегментации).

### Функция потерь
- `BCEWithLogitsLoss(pos_weight=5.0)` + `DiceLoss` (компенсация дисбаланса классов и оптимизация перекрытия).

### Обучение
- Оптимизатор: `AdamW(lr=lr 2e-4, weight_decay=1e-4)` (после выхода на плато дообучение на пониженном LR 5e-5).
- Mixed precision (AMP) + gradient accumulation: `batch=8`, `accum=4` (эффективный batch = 32).
- Gradient clipping: `max_grad_norm=1.0`.
- Resume и сохранение чекпойнтов: `best_model.pt` (лучший по IoU) и `last_model.pt`.

### Метрики
- Precision, Recall, IoU, F1 (по пикселям) после пороговой бинаризации вероятностей.

### Результаты
- На валидации в процессе дообучения: **IoU ~ 0.72–0.74**, **F1 ~ 0.83–0.85**.
- Лучший сохранённый чекпойнт: `best_iou ≈ 0.749` (epoch 47).

### Подбор порога для инференса
- Полный скан по порогам на val: лучший IoU при **thr = 0.78**  
  **IoU = 0.7413**, **P = 0.834**, **R = 0.870**, **F1 = 0.8514**.
- Проверка площади на val при `thr=0.78`: **Pred/GT ≈ 1.043** (≈ +4.3% площади относительно GT).
- **Лучший порог по площади (минимизация |Pred−GT|):** среди протестированных значений наиболее близкое совпадение площади даёт **thr = 0.80**  
  (Δ_area ≈ **+382,957 px**, **Pred/GT ≈ 1.026** на скане; площадь ближе к GT, но IoU практически не меняется: **IoU ≈ 0.7412**).

### Визуальная проверка
- Добавлен интерактивный просмотр (ipywidgets): выбор `best/last`, настройка порога, визуализация `GT / Pred / Overlay` + сравнение площадей.

## Эксперимент 2: U-Net с энкодером ResNet50 (transfer из DeepLabV3)

Ноутбук: 2. Buildings_UNet.ipynb

**Цель:** попробовать альтернативную архитектуру (U-Net) для бинарной сегментации зданий и улучшить качество относительно DeepLabV3 за счёт переносa признаков энкодера.

### Данные и пайплайн
- Используется тот же датасет `images/*.tif` + `gt/*.tif`, разбиение train/val = 85/15 (`seed=42`).
- Патчи **256×256**, чтение TIFF “окнами” (`rasterio`).
- Train: `scale jitter 0.5–1.5` + аугментации (flip, rot90).  
- Val: без jitter/аугментаций.
- Нормализация входа в **[0, 1]**, маска **0/255 → 0/1**.

### Модель
- **U-Net** с энкодером **ResNet50** (torchvision).  
- Выход: 1 канал логитов (`{"out": logits}`), чтобы совпасть с существующим training loop.

### Transfer learning (инициализация энкодера)
- Энкодер U-Net инициализируется весами из лучшего чекпойнта **DeepLabV3**:
  - из state_dict берутся ключи с префиксом `backbone.*` и загружаются в `model.encoder`.
- Декодер и голова U-Net — новые (обучаются с нуля).

### Функция потерь и метрики
- Loss: `BCEWithLogitsLoss(pos_weight=5.0)` + `DiceLoss`.
- Метрики: Precision / Recall / IoU / F1 (по пикселям), порог по умолчанию **thr=0.80**.

### Обучение
- `AdamW(weight_decay=1e-4)` с разными LR:
  - encoder: **1e-5** (очень маленький, чтобы не “сломать” признаки), после достижения плато снижаем до **3e-6**,
  - decoder/head: **1e-4** (выше, чтобы быстрее обучить декодер), после достижения плато снижаем до **3e-5**.
- AMP + gradient accumulation: `batch=8`, `accum=4` (эффективный batch=32).
- Gradient clipping: `max_grad_norm=1.0`.
- Resume из `/content/drive/MyDrive/Models/last_unet.pt`, сохранение `best_unet.pt` и `last_unet.pt`.

### Результаты (валидация)
- Лучший сохранённый чекпойнт: `best_iou ≈ 0.755` (epoch 50).

### Подбор порога для инференса
- Полный скан порогов на val показал лучший IoU при **thr = 0.80**:  
  **IoU = 0.7483**, **P = 0.842**, **R = 0.870**, **F1 = 0.8560**.
- **Лучший порог по площади (минимизация |Pred−GT| среди протестированных):** также **thr = 0.80**  
  (на скане Δ_area = **+467,899 px**, **Pred/GT = 1.033**).
- Итоговая проверка площади по всему val при `thr=0.80`: **Pred/GT ≈ 1.057** (≈ +5.7% площади относительно GT).

### Визуальная проверка
- Добавлен интерактивный просмотр (ipywidgets): выбор `best/last`, настройка порога, визуализация `GT / Pred / Overlay` + сравнение площадей.

## Эксперимент 3: Новая аугментация: имитация окклюзий “кронами деревьев”

Ноутбук: 3. Buildings_UNet_(trees).ipynb

- В `CropConfig` добавлены параметры `tree_*`, и в `_augment()` включена опция **tree occlusion**.
- Реализована функция `add_tree_blobs()`: поверх изображения накладываются полупрозрачные “пятна” (зелёные/иногда чёрные), сформированные из набора размытых кругов + шумовой текстуры.
- Центры пятен с вероятностью `tree_on_mask_prob` выбираются **по пикселям здания** (то есть окклюзия чаще закрывает здания, а не фон).

Параметры для train:
- `tree_p=0.30` (30% патчей с окклюзией)
- 2–6 пятен на патч (`tree_blobs`)
- радиусы 3–15 px (`tree_r_px`)
- непрозрачность 0.70–1.00 (`tree_alpha`)
- небольшое размытие `k=3..7` (`tree_blur_k`)
- `tree_black_prob=0.20`

Валидация: `tree_p=0.0` (без окклюзий).

### Порог для метрик и инференса
- Базовый порог в `metrics_from_logits()` и в визуализации изменён на **thr=0.86** (в прошлом ноутбуке был 0.80).
- Скан порогов смещён в “верхнюю” область: теперь тестируются **0.70–0.94** с шагами (0.70, 0.75, 0.80, 0.82, 0.84, 0.86, 0.88, 0.90, 0.92, 0.94).

### Результаты подбора порога (best U-Net)
- Лучший IoU на full val при **thr = 0.84**:  
  **IoU = 0.7581**, **P = 0.854**, **R = 0.871**, **F1 = 0.8624**.
- Лучший порог по площади (минимизация |Pred−GT| среди протестированных) — **thr = 0.86**:  
  на скане Δ_area = **−13,048 px**, **Pred/GT = 0.999** (практически идеальное совпадение площади).
- Полная проверка площади при `thr=0.84`: **Pred/GT ≈ 1.035** (≈ +3.5% площади относительно GT).

### Чекпойнты и прогресс обучения
- Продолжение обучения шло из `last_unet.pt` 
- После эпохи epoch=72 (best_iou ≈ 0.7612).

## Эксперимент 4: Регрессия GSD (оценка масштаба/разрешения) CNN моделью по патчам со спутниковых снимков

Ноутбук: 4. Buildings_UNet_(Scale) (mask only).ipynb

**Цель:** обучить модель, которая по изображению патча предсказывает **GSD (meters per pixel)**, чтобы далее корректно пересчитывать площадь зданий в физические единицы при разном масштабе/зуме/ресэмплинге.

### Данные и разбиение
- Используется тот же датасет сцен:
  - изображения: `dataset/images/*.tif`
  - маски зданий: `dataset/gt/*.tif` (те же имена файлов)
- Разбиение: train/val = **85/15** (`seed=42`).
- **Фильтрация пустых патчей:** при формировании выборки **отбрасываются** окна, где в маске нет зданий (`mask window sum == 0`).  
  Это важно, чтобы модель училась по информативным структурам (здания/контуры), а не по “пустому фону”.

### Пайплайн данных (GSD-датасет)
- Чтение больших TIFF “окнами” через `rasterio`, генерация патчей **на лету**.
- Размер выходного патча: **256×256**.
- Вводится “виртуальный zoom” **z**, который имитирует разные разрешения:
  - `z ~ U_log(0.25, 1.5)` (log-uniform sampling)
  - исходный размер окна: `src_sz ≈ patch_size / z`, затем ресайз обратно в 256×256
  - целевой GSD патча: `GSD = GSD0 / z`, где `GSD0 = 0.30 м/пикс` (базовый GSD тренировочного датасета)
- Таргет для регрессии: **log(GSD)** (стабильнее, мультипликативная шкала).
- Нормализация входа: изображение приводится к **[0, 1]**, поддерживаются `uint8/uint16/float` TIFF.

### Аугментации (anti-cheat, для устойчивости к “реальному миру”)
В train включены аугментации, которые имитируют разные источники данных и деградации:

- Геометрия: `flip`, `rot90`.
- Photometric jitter (с вероятностью `color_p=0.85`):
  - gamma: `0.85–1.15`
  - brightness/contrast/saturation: `±0.12`
- Blur: `p=0.20`, `sigma 0.2–1.0`
- Sharpen (unsharp mask): `p=0.12`, `amount 0.2–0.6`, `sigma 0.6–1.4`
- Noise: `p=0.30`, `std 0.0–0.02`
- JPEG-like деградация: `p=0.30`, квантование уровней (`q 32–128`) + downscale `0.6–1.0`
- “Shade” (мягкое затенение): `p=0.20`, сила `0.02–0.10`

Валидация:
- **scale jitter включён**, но **augment выключен** (чистая оценка, кроме изменения масштаба).

### Модель
- **ResNet50 encoder → регрессор GSD**
- Архитектура:
  - backbone: `resnet50(weights=None)` (fc удалён)
  - GAP (global average pooling) → MLP head:
    - `2048 → 256 → 1`
    - `Dropout=0.2`
- Выход: `{"t": pred_log_gsd}`, где `t = log(GSD)`.

### Transfer learning (инициализация энкодера из U-Net)
- Энкодер ResNet50 **инициализируется** из чекпойнта U-Net (из экспериментов 2–3):
  - из state_dict берутся ключи `encoder.*` (fallback: `model.encoder.*`)
  - загружаются в `gsd_model.encoder` (`strict=False`)
- Идея: признаки, полезные для сегментации зданий, должны помогать и задаче оценки масштаба (по характерным структурам и деталям).

### Функция потерь и метрики
- Loss: **SmoothL1 / Huber** по `log(GSD)` (`beta=0.05`)  
  Устойчивее MSE при широком диапазоне масштабов.
- Метрики считаются уже в **м/пикс** (после `exp()`):
  - **MAE (m/px)**
  - **RMSE (m/px)**
  - **MAPE (%)** = mean(|err| / true)

### Обучение
- Оптимизатор: `AdamW(weight_decay=1e-4)` с разными LR:
  - encoder: **3e-6** (минимальный, чтобы не “сломать” перенесённые признаки)
  - head: **3e-5**
- Mixed precision (AMP) + gradient accumulation:
  - `batch=8`, `accum=4` → эффективный batch = **32**
- Gradient clipping: `max_grad_norm=1.0`
- DataLoader:
  - `num_workers=2`, `pin_memory=True` (на CUDA), `persistent_workers=True`
  - `prefetch_factor=2`
  - `worker_init_fn` фиксирует seed и ограничивает потоки (ускорение/стабильность)

### Чекпойнты и резюмирование
- Сохранение:
  - `best_gsd.pt` — лучший по **MAE на val**
  - `last_gsd.pt` — последний чекпойнт
- Resume:
  - настраивается флагом `RESUME_FROM = "last" | "best"`
  - восстанавливаются `model_state_dict`, `optimizer_state_dict`, `scaler_state_dict` (если возможно)

### Контроль распределения масштаба (важно для sanity check)
- Добавлен быстрый просмотр распределения `GSD` в train/val:
  - строятся гистограммы и выводятся статистики (min/p05/median/p95/max)
- Это позволяет убедиться, что scale jitter действительно покрывает нужный диапазон.

### Визуальная и статистическая проверка качества
Добавлены интерактивные инструменты (ipywidgets):

1) **Просмотр батча (best/last):**
- выводит N изображений из val и подписи:
  - `true GSD`, `pred GSD`, `abs_err`, `rel_err%`

2) **Гистограммы ошибок:**
- распределение абсолютной ошибки (m/px)
- распределение относительной ошибки (%)
- печать summary (MAE/RMSE/MAPE + перцентили)
- доля сэмплов, где `abs_err <= {0.01, 0.02, 0.03, 0.05} m/px`

3) **Расширенная оценка:**
- scatter `pred vs true`
- зависимость `abs_err` от `true GSD`
- доп. метрика в log-пространстве:
  - `log-MAE` и оценка типичной мультипликативной ошибки `exp(log_mae)-1`

### Результаты
- В этом ноутбуке качество фиксируется метриками **MAE/RMSE/MAPE** на валидации.
- Лучший чекпойнт выбирается по **минимальному MAE** (m/px).

## Эксперимент 5: Инференс-стресс-тест CNN модели определения GSD на больших сценах со скользящим окном и агрегацией (mean vs median)

Ноутбук: 5. ScaleTest.ipynb

**Цель:** проверить, как модель **GSD-регрессии** (эксп. 4) ведёт себя в реалистичном сценарии инференса:
- берём **целую сцену** (val), 
- искусственно меняем “разрешение” (масштаб) **ресайзом всего изображения и маски**,
- режем на перекрывающиеся **256×256 окна**, оставляем только окна **с зданиями**,
- предсказываем GSD по каждому окну и агрегируем по сцене,
- сравниваем оценку с **истинным GSD после ресайза**.

### Данные и разбиение
- Используется val-разбиение того же датасета:
  - `dataset/images/*.tif`
  - `dataset/gt/*.tif`
- Разбиение: **train/val = 85/15** (`seed=42`).
- В эксперименте прогоняются **все val-сцены**: `n_images = 27`.

### Постановка эксперимента (симуляция разных GSD)
- Базовый масштаб датасета: `GSD0 = 0.30 м/пикс`.
- Для каждой val-сцены прогоняется набор **N_SCALES = 10** “разрешений”, равномерно по **истинному GSD**:
  - `GSD_true ∈ [0.30 .. 1.20] м/пикс` (шаг ≈ 0.10)
  - Для каждого `GSD_true` вычисляется `z = GSD0 / GSD_true`
  - Ресайз всей сцены и маски одним и тем же `z`
    - если `z < 1`: `area` (downscale)
    - если `z > 1`: `bicubic` (upscale, antialias=True где возможно)
- Таким образом симулируется, что исходная сцена “приходит” с другим GSD, а модель должна его восстановить.

### Пайплайн инференса (sliding windows)
- Патч: **256×256**
- Шаг: **stride = 128** (50% overlap)
- Для каждого окна:
  - берём соответствующее окно маски
  - **оставляем окно только если есть здания** (`(mask > 0).sum() >= 1`)
- Батч-инференс: `batch_size=32`
- Предсказания:
  - модель выдаёт `t = log(GSD_hat)`
  - переводим в метры/пикс: `GSD_hat = exp(clamp(t, -10, 10))`

### Модель
- Та же модель, что в эксперименте 4:
  - `ResNet50GSDRegressor`
- Чекпойнт: `best_gsd.pt`

### Агрегация предсказаний по сцене
Для каждой сцены и каждого масштаба получаем набор оконных предсказаний `GSD_hat_i` и считаем:

- `GSD_scene_mean = mean(GSD_hat_i)` (стримингово, без хранения всех значений)
- `GSD_scene_median = median(GSD_hat_i)` (хранение ограничено `MEDIAN_MAX_STORE = 200k`, чтобы не взорвать память)

Далее ошибки относительно истинного GSD после ресайза:

- `abs_err = |GSD_scene - GSD_true|`
- `rel_err_pct = abs_err / GSD_true * 100%`

### Метрики и отчёты
Собирается таблица `image × scale` с колонками:
- `gsd_true`, `z`, `(newW,newH)`, метод ресайза
- `kept_building_windows`, `pred_count`
- `gsd_mean`, `rel_err_mean_pct`
- `gsd_median`, `rel_err_median_pct`

Дополнительно строятся агрегаты:
- **по сценам** (ошибка по масштабам)
- **по “группам” сцен** (по префиксу имени: kitsap/chicago/vienna/austin/tyrol)
- **по scale_idx** (как меняется ошибка при ухудшении/улучшении GSD)
- гладкие поверхности ошибок через **NW kernel regression**:
  - `E[rel_err | predicted_gsd]`
  - `E[rel_err | predicted_gsd, mask_frac]`, где `mask_frac` — доля пикселей зданий на исходной маске сцены

## Результаты

### 1) Группы сцен (медианная ошибка по масштабам)
Агрегация по префиксу имени файла (robust-оценка через median по масштабам):

| group   | n_images | rel_err_median_median (%) | rel_err_mean_median (%) | preds_total |
|---------|----------|----------------------------|--------------------------|------------|
| kitsap  | 2        | 4.170473                   | 2.724372                 | 6,559      |
| chicago | 7        | 4.523442                   | 5.621863                 | 25,715     |
| vienna  | 7        | 4.735178                   | 5.781111                 | 25,343     |
| austin  | 6        | 5.250098                   | 5.631460                 | 18,919     |
| tyrol   | 5        | 7.492296                   | 7.120409                 | 11,390     |

**Наблюдения:**
- В среднем **median-агрегация** по окнам часто выигрывает у mean (особенно когда появляются “выбросы” по окнам).
- Есть исключения (например, kitsap и tyrol), где mean чуть лучше — это может зависеть от структуры сцены, доли зданий и характера шумов.

### 2) Ошибка по истинному масштабу (scale_idx = 1..10, GSD_true ≈ 0.30..1.20)
Сводка по всем val-сценам (27 сцен на каждый scale_idx), показана **медиана относительной ошибки** по сценам на данном масштабе:

| scale_idx | preds_total | rel_err_mean_med (%) | rel_err_median_med (%) |
|----------:|------------:|----------------------:|------------------------:|
| 1  (≈0.30 m/px) | 29134 | 11.6229 | 10.1900 |
| 2  (≈0.40 m/px) | 17224 | 3.8252  | 4.7052  |
| 3  (≈0.50 m/px) | 11403 | 4.8991  | 5.3313  |
| 4  (≈0.60 m/px) | 8050  | 4.8509  | 4.0401  |
| 5  (≈0.70 m/px) | 5905  | 4.5900  | 3.8542  |
| 6  (≈0.80 m/px) | 4636  | 3.8395  | **3.2333** |
| 7  (≈0.90 m/px) | 4076  | 5.2516  | 4.0115  |
| 8  (≈1.00 m/px) | 2962  | 6.1951  | 5.3276  |
| 9  (≈1.10 m/px) | 2495  | 8.6396  | 7.1803  |
| 10 (≈1.20 m/px) | 2041  | 12.9782 | 12.8612 |

**Ключевой вывод по масштабу:** ошибка имеет выраженную **U-образную** зависимость:
- хуже всего на “краях” (очень хорошо/очень плохо по GSD: ~0.30 и ~1.20),
- лучший диапазон — примерно **0.6–0.8 м/пикс** (scale_idx 4–6), где достигается минимум медианной ошибки (около **3–4%**).

Также видно, что при ухудшении разрешения (к большим GSD) резко падает `preds_total` (меньше окон) — и это добавляет нестабильности сценовой оценке.

### 3) Непрерывный анализ ошибок (kernel regression)
Добавлен анализ гладких зависимостей ошибки:

- **E[rel_err | predicted_gsd]** (1D): минимум ожидаемой ошибки лежит примерно в зоне **~0.6–0.8 m/px** по предсказанному GSD.
- **E[rel_err | predicted_gsd, mask_frac]** (2D): ошибка заметно зависит от доли зданий в сцене:
  - при очень маленьком `mask_frac` (мало “сигнала”) и на краях по GSD ошибка выше;
  - средние значения `mask_frac` дают наиболее стабильные оценки.

### Визуальная проверка / диагностика
- Таблицы:
  - `df_detail`: все строки `image × scale`
  - `df_img_summary`: агрегаты по сценам
  - `scale_summary`: агрегаты по scale_idx
- Графики:
  - `E[rel_err | predicted_gsd]` (1D)
  - heatmap `E[rel_err | predicted_gsd, mask_frac]` (2D)

### Итог
Этот эксперимент подтверждает, что GSD-регрессор **работает устойчиво**, а для агрегации по окнам чаще всего выгоднее **median**, чем mean. Ошибка существенно зависит от масштаба: наиболее стабильная зона — **средние GSD (~0.6–0.8 м/пикс)**, тогда как на крайних разрешениях точность падает.



